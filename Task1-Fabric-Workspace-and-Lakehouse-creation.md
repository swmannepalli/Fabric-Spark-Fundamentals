 [Home](README.md) -  [Next Task (Upload File To Lakehouse) >](Task2-Upload-DataSet-To-Lakehouse.md)

### Task 1: Fabric Workspace and Lakehouse creation

 In this task we create a workspace - FabricSparkWS and a lakehouse - LakehouseSpark

-------------------------------------------------------------------------------------------------------------------

1. **Open** Power BI/Fabric page in a new tab by clicking [HERE](https://app.powerbi.com/)


>**Note:** Make sure to login using non-prod external subscription credentials.

2. **Sign in** to Power BI.

	<img width="526" alt="image" src="https://github.com/swmannepalli/Fabric-Spark-Fundamentals/assets/84516667/596f23b3-4f3c-4e53-aa25-2f28f65f0f52">
 
	> **Note:** Use your Azure Active Directory credentials to login to Power BI.

3. In Power BI service **click** 'Workspaces'.

4. **Click** '+ New workspace' button.

	![image](https://github.com/swmannepalli/Fabric-Spark-Fundamentals/assets/84516667/20420270-ccbb-486c-8cf3-b4d032eca176)


5. **Enter** the name as 'FabricSparkWS', expand Advanced and select Trial under License mode  and **click** 'Apply'.

   ## IMPORTANT: If your trial capacity expired, create a Fabric capacity in Azure Portal. F2 SKU is sufficient for this lab.

>If name 'FabricSparkWS' is already taken, add some suffix to the end of the name for eg. 'FabricSparkWSTest'.

>Workspace name should not have any spaces.

6. In Power BI service **Click** '+ New' and then **select** 'More options'.

   <img width="343" alt="image" src="https://github.com/swmannepalli/MicrosoftFabric_HOL/assets/84516667/6b6af585-e359-4fca-bafa-bc37bcda342e">

7. In the new window **click** 'Lakehouse'under Data Engineering.

 <img width="395" alt="image" src="https://github.com/swmannepalli/Fabric-Spark-Fundamentals/assets/84516667/7ce5a685-ea4e-4f1d-8f64-dcdf58ad2da1">

8. **Enter** the name as 'LakehouseSpark'.

11. **Click** 'Create' button.


[Continue >](Task2-Upload-DataSet-To-Lakehouse.md)

